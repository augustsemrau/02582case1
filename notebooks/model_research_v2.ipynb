{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case One: Project Notebook\n",
    "By August and William"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading\n",
    "## Load data and remove nan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_realized = pd.read_csv('data/tree_realized_preprocessed_data.csv', index_col=0)\n",
    "tree_future = pd.read_csv('data/tree_future_preprocessed_data.csv', index_col=0)\n",
    "linear_realized = pd.read_csv('data/linear_realized_preprocessed_data.csv', index_col=0)\n",
    "linear_future = pd.read_csv('data/linear_future_preprocessed_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove target from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tree_realized.LoadFactor\n",
    "tree_realized = tree_realized.loc[:, tree_realized.columns != 'LoadFactor']\n",
    "linear_realized = linear_realized.loc[:, linear_realized.columns != 'LoadFactor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make copy of **SeatCapacity** for computing forecast accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_realized['SeatCapacityOriginal'] = tree_realized.SeatCapacity\n",
    "tree_future['SeatCapacityOriginal'] = tree_future.SeatCapacity\n",
    "linear_realized['SeatCapacityOriginal'] = linear_realized.SeatCapacity\n",
    "linear_future['SeatCapacityOriginal'] = linear_future.SeatCapacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_realized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_realized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data splitting\n",
    "## Split data into modeling data (will be training and validation) and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Make train/val set *0.8 and test *0.2\n",
    "def split_model_test(X, y, seed=0, shuffle=False, stratify=False):\n",
    "    if stratify:\n",
    "        X_model, X_test, y_model, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=shuffle, stratify=y)\n",
    "    else:\n",
    "        X_model, X_test, y_model, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=shuffle)\n",
    "    return X_model, X_test, y_model, y_test\n",
    "\n",
    "def split_train_val(X_m, y_m, seed=0, shuffle=False, stratify=False):\n",
    "    if stratify:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_m, y_m, test_size=0.25, random_state=seed, shuffle=shuffle, stratify=y_m)\n",
    "    else:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_m, y_m, test_size=0.25, random_state=seed, shuffle=shuffle)\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def seperate_SCO(X_train_model, X_val_test):\n",
    "    X_train_model_SCO, X_val_test_SCO = X_train_model.SeatCapacityOriginal, X_val_test.SeatCapacityOriginal\n",
    "\n",
    "    X_train_model = X_train_model.loc[:, ~X_train_model.columns.isin(['SeatCapacityOriginal'])]\n",
    "    X_val_test = X_val_test.loc[:, ~X_val_test.columns.isin(['SeatCapacityOriginal'])]\n",
    "\n",
    "    return X_train_model, X_val_test, X_train_model_SCO, X_val_test_SCO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define validation setup for different models\n",
    "## Define forecast accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_forecast_accuracy(loadfactor_forecasted, loadfactor_true, seatcapacity):\n",
    "\n",
    "    passengers_true = loadfactor_true * seatcapacity\n",
    "    passengers_forecasted = loadfactor_forecasted * seatcapacity\n",
    "    \n",
    "    abs_deviation_per_flight = np.abs((passengers_true-passengers_forecasted) / passengers_true)\n",
    "    abs_deviation_per_flight[abs_deviation_per_flight >= 10000] = 100\n",
    "\n",
    "    mean_forecast_acc = np.mean(1 - abs_deviation_per_flight*1)*100\n",
    "    return mean_forecast_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define normalizer for training on **SeatCapacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_seatcapacity_fit(X_train):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train.SeatCapacity.values.reshape(-1, 1))\n",
    "    X_train.SeatCapacity = scaler.transform(X_train.SeatCapacity.values.reshape(-1, 1))\n",
    "    return X_train, scaler\n",
    "\n",
    "def normalize_seatcapacity(X_val, scaler):\n",
    "    X_val.SeatCapacity = scaler.transform(X_val.SeatCapacity.values.reshape(-1, 1))\n",
    "    return X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for fitting+validating models, as well as testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make function for fitting and validating model\n",
    "def fit_evaluate_model(X_tr_m, X_v_te, y_tr_m, y_v_te, model):\n",
    "    \n",
    "    ## Remove original seatcapacity\n",
    "    X_tr_m, X_v_te, X_tr_m_SCO, X_v_te_SCO = seperate_SCO(X_train_model=X_tr_m, X_val_test=X_v_te)\n",
    "\n",
    "    ## Normalize seatcapacity\n",
    "    X_tr_m, fitted_scaler = normalize_seatcapacity_fit(X_train=X_tr_m)\n",
    "    ## Fit model to the training data\n",
    "    model.fit(X=X_tr_m, y=y_tr_m)\n",
    "\n",
    "    ## Normalize validation data SeatCapacity for predictions\n",
    "    X_v_te = normalize_seatcapacity(X_val=X_v_te, scaler=fitted_scaler)\n",
    "    ## Make predictions\n",
    "    pred = model.predict(X_v_te)\n",
    "\n",
    "    ## Compute forecasting accuracy\n",
    "    acc = mean_forecast_accuracy(loadfactor_forecasted=pred, loadfactor_true=y_v_te.to_numpy(), seatcapacity=X_v_te_SCO.to_numpy())\n",
    "\n",
    "    return acc, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute EPE ground function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle = True\n",
    "# M = 100\n",
    "# forecast_acc = []\n",
    "\n",
    "# for m in range(M):\n",
    "\n",
    "#     ## Split data\n",
    "#     seed = np.random.randint(10000)\n",
    "#     X_model, X_test, y_model, y_test = split_model_test(X=X, y=y, seed=seed, shuffle=shuffle)\n",
    "#     X_train, X_val, y_train, y_val = split_train_val(X_m=X_model, y_m=y_model, seed=seed, shuffle=shuffle)\n",
    "\n",
    "#     ## Train model on training data with different model parameters\n",
    "#     #TODO MODEL TRAINING FUNCTION\n",
    "#     val_accs, best_model = \n",
    "\n",
    "#     ## Evaluate best model on test data\n",
    "#     test_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=best_model)\n",
    "#     forecast_acc.append(test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model: Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = linear_realized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_elastic_model(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    val_accs = {}\n",
    "    alphas = np.linspace(0,20,20)\n",
    "    for a in alphas[1:]:\n",
    "        model = ElasticNet(alpha=a, l1_ratio=0.5)\n",
    "        val_acc, model = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_val, y_tr_m=y_train, y_v_te=y_val, model=model)\n",
    "        val_accs[a] = val_acc\n",
    "\n",
    "\n",
    "    return val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "shuffle = True\n",
    "X_model, X_test, y_model, y_test = split_model_test(X=X, y=y, seed=seed, shuffle=shuffle)\n",
    "X_train, X_val, y_train, y_val = split_train_val(X_m=X_model, y_m=y_model, seed=seed, shuffle=shuffle)\n",
    "accs = find_best_elastic_model(X_train=X_train, X_val=X_val, y_train=y_train, y_val=y_val)\n",
    "\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "M = 100\n",
    "forecast_acc = []\n",
    "\n",
    "for m in range(M):\n",
    "\n",
    "    ## Split data\n",
    "    seed = np.random.randint(10000)\n",
    "    X_model, X_test, y_model, y_test = split_model_test(X=X, y=y, seed=seed, shuffle=shuffle)\n",
    "    X_train, X_val, y_train, y_val = split_train_val(X_m=X_model, y_m=y_model, seed=seed, shuffle=shuffle)\n",
    "\n",
    "    ## Train model on training data with different model parameters\n",
    "    #TODO MODEL TRAINING FUNCTION\n",
    "    # val_accs, best_model = \n",
    "    model = ElasticNet(alpha=1, l1_ratio=0.5)\n",
    "\n",
    "    ## Evaluate best model on test data\n",
    "    test_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=model)\n",
    "    forecast_acc.append(test_acc)\n",
    "\n",
    "\n",
    "print(f'Mean of test accuracies: {np.mean(forecast_acc)}\\nStd. of test accuracies: {np.var(forecast_acc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Models: Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_xgboost_model(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    val_accs = {}\n",
    "    alphas = np.linspace(0,20,20)\n",
    "    for a in alphas[1:]:\n",
    "        model = XGBRegressor(max_depth=int(a))\n",
    "        val_acc, model = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_val, y_tr_m=y_train, y_v_te=y_val, model=model)\n",
    "        val_accs[a] = val_acc\n",
    "\n",
    "\n",
    "    return val_accs, max(val_accs, key=val_accs.get)\n",
    "\n",
    "seed = 1\n",
    "shuffle = False\n",
    "X_model, X_test, y_model, y_test = split_model_test(X=X, y=y, seed=seed, shuffle=shuffle)\n",
    "X_train, X_val, y_train, y_val = split_train_val(X_m=X_model, y_m=y_model, seed=seed, shuffle=shuffle)\n",
    "accs, max_acc = find_best_xgboost_model(X_train=X_train, X_val=X_val, y_train=y_train, y_val=y_val)\n",
    "\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tree_realized\n",
    "\n",
    "shuffle = True\n",
    "M = 100\n",
    "config_defaults = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"shuffle\": True,\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.2,\n",
    "    \"subsample\": 0.5\n",
    "    }\n",
    "\n",
    "\n",
    "forecast_acc = []\n",
    "\n",
    "for m in range(M):\n",
    "\n",
    "    ## Split data\n",
    "    seed = np.random.randint(10000)\n",
    "    X_model, X_test, y_model, y_test = split_model_test(X=X, y=y, seed=seed, shuffle=shuffle)\n",
    "    X_train, X_val, y_train, y_val = split_train_val(X_m=X_model, y_m=y_model, seed=seed, shuffle=shuffle)\n",
    "    # print(f'Shape X_model = {X_train.shape}')\n",
    "\n",
    "    ## Train model on training data with different model parameters\n",
    "    #TODO MODEL TRAINING FUNCTION\n",
    "    # val_accs, best_model = \n",
    "    model = XGBRegressor(booster=config.booster, \n",
    "                        max_depth=config.max_depth,\n",
    "                        learning_rate=config.learning_rate, \n",
    "                        subsample=config.subsample, \n",
    "                        tree_method=config.tree_method)\n",
    "\n",
    "    ## Evaluate best model on test data\n",
    "    test_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=model)\n",
    "    forecast_acc.append(test_acc)\n",
    "\n",
    "\n",
    "print(f'Mean of test accuracies: {np.mean(forecast_acc)}\\nStd. of test accuracies: {np.var(forecast_acc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make WandB Sweeps to preliminarily find best ranges for parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tree_realized\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"random\", # try grid or random\n",
    "    \"metric\": {\n",
    "      \"name\": \"accuracy\",\n",
    "      \"goal\": \"maximize\"   \n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"max_depth\": {\n",
    "            \"values\": [6, 7, 8, 9]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [0.1, 0.15, 0.2]\n",
    "        },\n",
    "        \"subsample\": {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='02582_case1_1', entity='tgml')\n",
    "\n",
    "def train():\n",
    "    config_defaults = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"shuffle\": True,\n",
    "    \"tree_method\": \"gpu_hist\"\n",
    "    }\n",
    "\n",
    "    wandb.init(project='02582_case1_1', entity='tgml', config=config_defaults)  # defaults are over-ridden during the sweep\n",
    "    config = wandb.config\n",
    "\n",
    "    X_model, X_test, y_model, y_test = split_model_test(X=X, y=y, seed=config.seed, shuffle=config.shuffle, stratify=False)\n",
    "    X_train, X_val, y_train, y_val = split_train_val(X_m=X_model, y_m=y_model, seed=config.seed, shuffle=config.shuffle, stratify=False)\n",
    "\n",
    "    # fit model on train\n",
    "    model = XGBRegressor(booster=config.booster, max_depth=config.max_depth,\n",
    "                            learning_rate=config.learning_rate, subsample=config.subsample, tree_method=config.tree_method)\n",
    "\n",
    "    # model_on_test_acc, _ = fit_evaluate_model(X_tr_m=X_model, X_v_te=X_test, y_tr_m=y_model, y_v_te=y_test, model=model)\n",
    "    # train_on_test_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=model)\n",
    "    train_on_val_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_val, y_tr_m=y_train, y_v_te=y_val, model=model)\n",
    "\n",
    "    wandb.log({\"accuracy\": train_on_val_acc})\n",
    "#objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, alpha = 10, n_estimators = 10\n",
    "\n",
    "wandb.agent(sweep_id, train, count=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tree_realized\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"random\", # try grid or random\n",
    "    \"metric\": {\n",
    "      \"name\": \"accuracy\",\n",
    "      \"goal\": \"maximize\"   \n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"n_estimators\": {\n",
    "            \"values\": [1800, 2000, 2400, 2800]\n",
    "        },\n",
    "        \"max_depth\": {\n",
    "            \"values\": [20, 30, 40, 50]\n",
    "            # \"distribution\": \"uniform\",\n",
    "            # \"min\": 0.00001,\n",
    "            # \"max\": 1\n",
    "        },\n",
    "        \"min_samples_split\": {\n",
    "            \"values\": [2,5,10]\n",
    "        },\n",
    "        \"min_samples_leaf\": {\n",
    "            \"values\": [1,2,4]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='02582_case1_rf', entity='tgml')\n",
    "\n",
    "def train():\n",
    "    config_defaults = {'bootstrap': True,\n",
    "    'criterion': 'mse',\n",
    "    'max_depth': None,\n",
    "    'max_features': 'auto',\n",
    "    'max_leaf_nodes': None,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_impurity_split': None,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'n_estimators': 10,\n",
    "    'n_jobs': 1,\n",
    "    'oob_score': False,\n",
    "    'random_state': 42,\n",
    "    'verbose': 0,\n",
    "    'warm_start': False,\n",
    "    \"seed\": 0,\n",
    "    \"shuffle\": True}\n",
    "\n",
    "    wandb.init(project='02582_case1_1', entity='tgml', config=config_defaults)  # defaults are over-ridden during the sweep\n",
    "    config = wandb.config\n",
    "\n",
    "    X_model, X_test, y_model, y_test = split_model_test(X=X, y=y, seed=config.seed, shuffle=config.shuffle, stratify=False)\n",
    "    X_train, X_val, y_train, y_val = split_train_val(X_m=X_model, y_m=y_model, seed=config.seed, shuffle=config.shuffle, stratify=False)\n",
    "\n",
    "    # fit model on train\n",
    "    model = RandomForestRegressor(n_estimators=config.n_estimators, max_features=config.max_features,\n",
    "                            max_depth=config.max_depth, min_samples_split=config.min_samples_split, min_samples_leaf=config.min_samples_leaf)\n",
    "\n",
    "    # model_on_test_acc, _ = fit_evaluate_model(X_tr_m=X_model, X_v_te=X_test, y_tr_m=y_model, y_v_te=y_test, model=model)\n",
    "    # train_on_test_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=model)\n",
    "    train_on_val_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_val, y_tr_m=y_train, y_v_te=y_val, model=model)\n",
    "\n",
    "    wandb.log({\"accuracy\": train_on_val_acc})\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, train, count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize WandB for logging config and metrics\n",
    "wandb.init(project='02582_case1_1', entity='tgml', config=wandb_config)\n",
    "\n",
    "## Split data\n",
    "seed = np.random.randint(10000)\n",
    "X_model, X_test, y_model, y_test = split_model_test(X=X, y=y, seed=seed, shuffle=shuffle)\n",
    "X_train, X_val, y_train, y_val = split_train_val(X_m=X_model, y_m=y_model, seed=seed, shuffle=shuffle)\n",
    "\n",
    "## Train model on training data with different model parameters\n",
    "model = XGBRegressor(max_depth=wandb_config['max_depth'], tree_method=wandb_config['tree_method'])\n",
    "\n",
    "model_on_test_acc, _ = fit_evaluate_model(X_tr_m=X_model, X_v_te=X_test, y_tr_m=y_model, y_v_te=y_test, model=model)\n",
    "## Evaluate best model on test data\n",
    "train_on_test_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=model)\n",
    "\n",
    "wandb.log({'model_on_test_acc':model_on_test_acc, 'train_on_test_acc': train_on_test_acc})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
