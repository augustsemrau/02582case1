{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case One: Project Notebook\n",
    "By August and William"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Data Loading\n",
    "# `train.csv`\n",
    "# `validation.csv`\n",
    "# `test.csv`\n",
    "# `future_preprocessed.csv`\n",
    "real_train = pd.read_csv('data/train.csv', index_col=0)\n",
    "real_val = pd.read_csv('data/validation.csv', index_col=0)\n",
    "real_test = pd.read_csv('data/test.csv', index_col=0)\n",
    "\n",
    "future = pd.read_csv('data/future_preprocessed.csv', index_col=0)\n",
    "\n",
    "# Remove target from data\n",
    "y_train = real_train.LoadFactor\n",
    "real_train = real_train.loc[:, real_train.columns != 'LoadFactor']\n",
    "y_val = real_val.LoadFactor\n",
    "real_val = real_val.loc[:, real_val.columns != 'LoadFactor']\n",
    "\n",
    "## Make copy of **SeatCapacity** for computing forecast accuracy\n",
    "real_train['SeatCapacityOriginal'] = real_train.SeatCapacity\n",
    "real_val['SeatCapacityOriginal'] = real_val.SeatCapacity\n",
    "real_test['SeatCapacityOriginal'] = real_test.SeatCapacity\n",
    "# future['SeatCapacityOriginal'] = future.SeatCapacity\n",
    "\n",
    "X_train = real_train\n",
    "X_val = real_val\n",
    "\n",
    "\n",
    "# # 3. Data splitting\n",
    "# ## Split data into modeling data (will be training and validation) and test data\n",
    "\n",
    "# ### Make train/val set *0.8 and test *0.2\n",
    "# def split_model_test(X, y, seed=0, shuffle=False, stratify=False):\n",
    "#     if stratify:\n",
    "#         X_model, X_test, y_model, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=shuffle, stratify=y)\n",
    "#     else:\n",
    "#         X_model, X_test, y_model, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=shuffle)\n",
    "#     return X_model, X_test, y_model, y_test\n",
    "\n",
    "# def split_train_val(X_m, y_m, seed=0, shuffle=False, stratify=False):\n",
    "#     if stratify:\n",
    "#         X_train, X_val, y_train, y_val = train_test_split(X_m, y_m, test_size=0.25, random_state=seed, shuffle=shuffle, stratify=y_m)\n",
    "#     else:\n",
    "#         X_train, X_val, y_train, y_val = train_test_split(X_m, y_m, test_size=0.25, random_state=seed, shuffle=shuffle)\n",
    "#     return X_train, X_val, y_train, y_val\n",
    "\n",
    "def seperate_SCO(X_train_model, X_val_test):\n",
    "    X_train_model_SCO, X_val_test_SCO = X_train_model.SeatCapacityOriginal, X_val_test.SeatCapacityOriginal\n",
    "\n",
    "    X_train_model = X_train_model.loc[:, ~X_train_model.columns.isin(['SeatCapacityOriginal'])]\n",
    "    X_val_test = X_val_test.loc[:, ~X_val_test.columns.isin(['SeatCapacityOriginal'])]\n",
    "\n",
    "    return X_train_model, X_val_test, X_train_model_SCO, X_val_test_SCO\n",
    "\n",
    "\n",
    "# 4. Define validation setup for different models\n",
    "## Define forecast accuracy function\n",
    "def mean_forecast_accuracy(loadfactor_forecasted, loadfactor_true, seatcapacity):\n",
    "\n",
    "    passengers_true = loadfactor_true * seatcapacity\n",
    "    passengers_forecasted = loadfactor_forecasted * seatcapacity\n",
    "    \n",
    "    abs_deviation_per_flight = np.abs((passengers_true-passengers_forecasted) / passengers_true)\n",
    "    abs_deviation_per_flight[abs_deviation_per_flight >= 10000] = 100\n",
    "\n",
    "    mean_forecast_acc = np.mean(1 - abs_deviation_per_flight*1)*100\n",
    "    return mean_forecast_acc\n",
    "\n",
    "## Define normalizer for training on **SeatCapacity**\n",
    "def normalize_seatcapacity_fit(X_train):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train.SeatCapacity.values.reshape(-1, 1))\n",
    "    X_train.SeatCapacity = scaler.transform(X_train.SeatCapacity.values.reshape(-1, 1))\n",
    "    return X_train, scaler\n",
    "\n",
    "def normalize_seatcapacity(X_val, scaler):\n",
    "    X_val.SeatCapacity = scaler.transform(X_val.SeatCapacity.values.reshape(-1, 1))\n",
    "    return X_val\n",
    "\n",
    "## Functions for fitting+validating models, as well as testing models\n",
    "### Make function for fitting and validating model\n",
    "def fit_evaluate_model(X_tr_m, X_v_te, y_tr_m, y_v_te, model):\n",
    "    \n",
    "    ## Remove original seatcapacity\n",
    "    X_tr_m, X_v_te, X_tr_m_SCO, X_v_te_SCO = seperate_SCO(X_train_model=X_tr_m, X_val_test=X_v_te)\n",
    "\n",
    "    # ## Normalize seatcapacity\n",
    "    # X_tr_m, fitted_scaler = normalize_seatcapacity_fit(X_train=X_tr_m)\n",
    "    ## Fit model to the training data\n",
    "    model.fit(X=X_tr_m, y=y_tr_m)\n",
    "\n",
    "    # ## Normalize validation data SeatCapacity for predictions\n",
    "    # X_v_te = normalize_seatcapacity(X_val=X_v_te, scaler=fitted_scaler)\n",
    "    ## Make predictions\n",
    "    pred = model.predict(X_v_te)\n",
    "\n",
    "    ## Compute forecasting accuracy\n",
    "    acc = mean_forecast_accuracy(loadfactor_forecasted=pred, loadfactor_true=y_v_te.to_numpy(), seatcapacity=X_v_te_SCO.to_numpy())\n",
    "\n",
    "    return acc, model\n",
    "\n",
    "def evaluate_model(X_tr_m, X_v_te, y_tr_m, y_v_te, model):\n",
    "    \n",
    "    ## Remove original seatcapacity\n",
    "    X_tr_m, X_v_te, X_tr_m_SCO, X_v_te_SCO = seperate_SCO(X_train_model=X_tr_m, X_val_test=X_v_te)\n",
    "\n",
    "    # ## Normalize seatcapacity\n",
    "    # X_tr_m, fitted_scaler = normalize_seatcapacity_fit(X_train=X_tr_m)\n",
    "\n",
    "    # ## Normalize validation data SeatCapacity for predictions\n",
    "    # X_v_te = normalize_seatcapacity(X_val=X_v_te, scaler=fitted_scaler)\n",
    "    ## Make predictions\n",
    "    pred = model.predict(X_v_te)\n",
    "\n",
    "    ## Compute forecasting accuracy\n",
    "    acc = mean_forecast_accuracy(loadfactor_forecasted=pred, loadfactor_true=y_v_te.to_numpy(), seatcapacity=X_v_te_SCO.to_numpy())\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Find best hyperparameters using val set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"random\", # try grid or random\n",
    "    \"metric\": {\n",
    "      \"name\": \"accuracy\",\n",
    "      \"goal\": \"maximize\"   \n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"n_estimators\": {\n",
    "            \"values\": [400, 800, 1200, 1600, 2000, 2500, 3000]\n",
    "        },\n",
    "        \"max_depth\": {\n",
    "            \"values\": [3,4,5,6,7,9,11]\n",
    "            # \"distribution\": \"uniform\",\n",
    "            # \"min\": 0.00001,\n",
    "            # \"max\": 1\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [0.05, 0.1, 0.15, 0.2]\n",
    "        },\n",
    "        \"subsample\": {\n",
    "            \"values\": [0.25, 0.5, 0.75, 1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='02582_case1_boost_sweep', entity='tgml')\n",
    "\n",
    "def train():\n",
    "    config_defaults = {\n",
    "    # 'bootstrap': True,\n",
    "    # 'criterion': 'mse',\n",
    "    # 'max_features': 'auto',\n",
    "    # 'max_leaf_nodes': None,\n",
    "    # 'min_impurity_decrease': 0.0,\n",
    "    # 'min_impurity_split': None,\n",
    "    # 'min_samples_leaf': 1,\n",
    "    # 'min_samples_split': 2,\n",
    "    # 'min_weight_fraction_leaf': 0.0,\n",
    "    # 'n_estimators': 10,\n",
    "    # 'n_jobs': 1,\n",
    "    # 'oob_score': False,\n",
    "    # 'random_state': 42,\n",
    "    # 'verbose': 0,\n",
    "    # 'warm_start': False,\n",
    "    \"seed\": 0,\n",
    "    \"n_estimators\": 100,\n",
    "    'max_depth': 3,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 0.5,\n",
    "    }\n",
    "\n",
    "    wandb.init(project='02582_case1_boost_sweep', entity='tgml', config=config_defaults)  # defaults are over-ridden during the sweep\n",
    "    config = wandb.config\n",
    "\n",
    "    # fit model on train\n",
    "    model = GradientBoostingRegressor(n_estimators=config.n_estimators, \n",
    "                                        learning_rate=config.learning_rate,\n",
    "                                        max_depth=config.max_depth,\n",
    "                                        subsample=config.subsample)\n",
    "\n",
    "    train_on_val_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_val, y_tr_m=y_train, y_v_te=y_val, model=model)\n",
    "\n",
    "    wandb.log({\"accuracy\": train_on_val_acc})\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, train, count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"random\", # try grid or random\n",
    "    \"metric\": {\n",
    "      \"name\": \"accuracy\",\n",
    "      \"goal\": \"maximize\"   \n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"n_estimators\": {\n",
    "            \"values\": [1800, 2000, 2400, 2800]\n",
    "        },\n",
    "        \"max_depth\": {\n",
    "            \"values\": [20, 30, 40, 50]\n",
    "        },\n",
    "        \"min_samples_split\": {\n",
    "            \"values\": [2,5,10]\n",
    "        },\n",
    "        \"min_samples_leaf\": {\n",
    "            \"values\": [1,2,4]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='02582_case1_rf_sweep', entity='tgml')\n",
    "\n",
    "def train():\n",
    "    config_defaults = {\n",
    "    'bootstrap': True,\n",
    "    'criterion': 'mse',\n",
    "    'max_depth': None,\n",
    "    'max_features': 'auto',\n",
    "    'max_leaf_nodes': None,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_impurity_split': None,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'n_estimators': 10,\n",
    "    'n_jobs': 1,\n",
    "    'oob_score': False,\n",
    "    'random_state': 42,\n",
    "    'verbose': 0,\n",
    "    'warm_start': False,\n",
    "    \"seed\": 0,\n",
    "    \"shuffle\": True}\n",
    "\n",
    "    wandb.init(project='02582_case1_rf_sweep', entity='tgml', config=config_defaults)  # defaults are over-ridden during the sweep\n",
    "    config = wandb.config\n",
    "\n",
    "\n",
    "    # fit model on train\n",
    "    model = RandomForestRegressor(n_estimators=config.n_estimators, bootstrap=config.bootstrap,\n",
    "                            max_depth=config.max_depth, min_samples_split=config.min_samples_split, min_samples_leaf=config.min_samples_leaf)\n",
    "\n",
    "    # model_on_test_acc, _ = fit_evaluate_model(X_tr_m=X_model, X_v_te=X_test, y_tr_m=y_model, y_v_te=y_test, model=model)\n",
    "    # train_on_test_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=model)\n",
    "    train_on_val_acc, _ = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_val, y_tr_m=y_train, y_v_te=y_val, model=model)\n",
    "\n",
    "    wandb.log({\"accuracy\": train_on_val_acc})\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, train, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now make accuracy prediction using test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "M = 1000\n",
    "config = {\n",
    "    'n_estimators': 10,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2,\n",
    "    }\n",
    "\n",
    "np.random.seed(0)\n",
    "forecast_acc = []\n",
    "\n",
    "wandb.init(project='02582_case1_final', entity='tgml', config=config, group='SKLEARN_GB')\n",
    "\n",
    "## Train and evaluate model\n",
    "model = GradientBoostingRegressor(n_estimators=config['n_estimators'], \n",
    "                                max_features=config['max_features'],\n",
    "                                max_depth=config['max_depth'], \n",
    "                                min_samples_split=config['min_samples_split'], \n",
    "                                min_samples_leaf=config['min_samples_leaf'])\n",
    "\n",
    "## Evaluate best model on test data\n",
    "test_acc, fitted_model = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=model)\n",
    "for m in range(M):\n",
    "\n",
    "    ## Sample from test set\n",
    "    seed = np.random.randint(10000)\n",
    "    real_test_sampled = real_test\n",
    "    real_test_sampled = real_test_sampled.sample(n=len(real_test), replace=True, random_state=seed)\n",
    "    y_test = real_test_sampled.LoadFactor\n",
    "    X_test = real_test_sampled.loc[:, real_test.columns != 'LoadFactor']\n",
    "\n",
    "    test_acc = evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=fitted_model)\n",
    "    forecast_acc.append(test_acc)\n",
    "    wandb.log({\"accuracy\": test_acc})\n",
    "\n",
    "\n",
    "print(f'Mean of test accuracies: {np.mean(forecast_acc)}\\nStd. of test accuracies: {np.var(forecast_acc)}')\n",
    "\n",
    "print(f'Mean of test accuracies: {np.mean(forecast_acc)}\\nStd. of test accuracies: {np.var(forecast_acc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "M = 1000\n",
    "config = {\n",
    "    # 'bootstrap': True,\n",
    "    # 'criterion': 'mse',\n",
    "    # 'max_leaf_nodes': None,\n",
    "    # 'min_impurity_decrease': 0.0,\n",
    "    # 'min_impurity_split': None,\n",
    "    # 'min_weight_fraction_leaf': 0.0,\n",
    "    # 'n_jobs': 1,\n",
    "    # 'oob_score': False,\n",
    "    # 'random_state': 42,\n",
    "    # 'verbose': 0,\n",
    "    # 'warm_start': False,\n",
    "    # \"shuffle\": True,\n",
    "    'max_features': 'auto',\n",
    "    'n_estimators': 2000,\n",
    "    'max_depth': 30,\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 4,\n",
    "    }\n",
    "\n",
    "np.random.seed(0)\n",
    "forecast_acc = []\n",
    "\n",
    "wandb.init(project='02582_case1_final', entity='tgml', config=config, group='RF')\n",
    "\n",
    "## Train and evaluate model\n",
    "model = RandomForestRegressor(n_estimators=config['n_estimators'], \n",
    "                                max_features=config['max_features'],\n",
    "                                max_depth=config['max_depth'], \n",
    "                                min_samples_split=config['min_samples_split'], \n",
    "                                min_samples_leaf=config['min_samples_leaf'])\n",
    "\n",
    "## Evaluate best model on test data\n",
    "test_acc, fitted_model = fit_evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=model)\n",
    "\n",
    "for m in range(M):\n",
    "\n",
    "    ## Sample from test set\n",
    "    seed = np.random.randint(10000)\n",
    "    real_test_sampled = real_test\n",
    "    real_test_sampled = real_test_sampled.sample(n=len(real_test), replace=True, random_state=seed)\n",
    "    y_test = real_test_sampled.LoadFactor\n",
    "    X_test = real_test_sampled.loc[:, real_test.columns != 'LoadFactor']\n",
    "\n",
    "    test_acc = evaluate_model(X_tr_m=X_train, X_v_te=X_test, y_tr_m=y_train, y_v_te=y_test, model=fitted_model)\n",
    "    forecast_acc.append(test_acc)\n",
    "    wandb.log({\"accuracy\": test_acc})\n",
    "\n",
    "\n",
    "print(f'Mean of test accuracies: {np.mean(forecast_acc)}\\nStd. of test accuracies: {np.var(forecast_acc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We now have the best model, make predictions and save to output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realized = pd.read_csv('data/realized_preprocessed_data.csv', index_col=0)\n",
    "future = pd.read_csv('data/future_preprocessed_data.csv', index_col=0)\n",
    "\n",
    "# Remove target from data\n",
    "y = realized.LoadFactor\n",
    "realized = realized.loc[:, realized.columns != 'LoadFactor']\n",
    "\n",
    "X = realized\n",
    "\n",
    "# Fit model\n",
    "X_tr_m, fitted_scaler = normalize_seatcapacity_fit(X_train=X)\n",
    "\n",
    "## Fit model to the training data\n",
    "model.fit(X=X y=y)\n",
    "\n",
    "## Normalize validation data SeatCapacity for predictions\n",
    "X_future = normalize_seatcapacity(X_val=future, scaler=fitted_scaler)\n",
    "## Make predictions\n",
    "pred = model.predict(X_future)\n",
    "\n",
    "prediction_file = future\n",
    "prediction_file['LoadFactor'] = pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file.to_txt('output.txt', sep=',', decimal='.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
